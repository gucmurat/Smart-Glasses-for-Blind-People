{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb08145a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\ege/.cache\\torch\\hub\\intel-isl_MiDaS_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights:  None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\ege/.cache\\torch\\hub\\rwightman_gen-efficientnet-pytorch_master\n",
      "Using cache found in C:\\Users\\ege/.cache\\torch\\hub\\intel-isl_MiDaS_master\n",
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n",
      "D:\\anaconda3\\Lib\\site-packages\\transformers\\models\\vit\\feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nwith NumpySocket() as s:\\n    s.bind((HOST, PORT))\\n\\n    while True:\\n        try:\\n            s.listen()\\n            logger.info(\"Started to listen port.\")\\n            conn, addr = s.accept()\\n\\n            logger.info(f\"connection approved: {addr}\")\\n            while conn:\\n                array_of_frames = conn.recv()\\n                if len(array_of_frames) == 0:\\n                    break\\n                frame_right = array_of_frames[0]\\n                frame_left = array_of_frames[1]\\n                \\n                cv2.imshow(\"output\", frame_right)\\n                cv2.imshow(\"output\", frame_left)\\n                if cv2.waitKey(1) & 0xFF == ord(\\'q\\'):\\n                    break\\n            logger.info(f\"disconnection:: {addr}\")\\n        except ConnectionResetError:\\n            pass\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from numpysocket import NumpySocket\n",
    "import cv2\n",
    "import logging\n",
    "import evaluation\n",
    "\n",
    "evaluation.initialize_models()\n",
    "\n",
    "HOST = ''\n",
    "PORT = 9999\n",
    "\n",
    "logger = logging.getLogger(\"OpenCV server\")\n",
    "logger.setLevel(logging.INFO)\n",
    "\"\"\"\n",
    "with NumpySocket() as s:\n",
    "    s.bind((HOST, PORT))\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            s.listen()\n",
    "            logger.info(\"Started to listen port.\")\n",
    "            conn, addr = s.accept()\n",
    "\n",
    "            logger.info(f\"connection approved: {addr}\")\n",
    "            while conn:\n",
    "                array_of_frames = conn.recv()\n",
    "                if len(array_of_frames) == 0:\n",
    "                    break\n",
    "                frame_right = array_of_frames[0]\n",
    "                frame_left = array_of_frames[1]\n",
    "                \n",
    "                cv2.imshow(\"output\", frame_right)\n",
    "                cv2.imshow(\"output\", frame_left)\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "            logger.info(f\"disconnection:: {addr}\")\n",
    "        except ConnectionResetError:\n",
    "            pass\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbb0342c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\ege\\Desktop\\calibration_images\\1\\left.png: 480x640 1 bottle, 578.6ms\n",
      "Speed: 2.3ms preprocess, 578.6ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\ege\\Desktop\\calibration_images\\1\\right.png: 480x640 1 bottle, 512.8ms\n",
      "Speed: 2.0ms preprocess, 512.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'names'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m image_info1 \u001b[38;5;241m=\u001b[39m evaluation\u001b[38;5;241m.\u001b[39mstereo_vision_distance_result(cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/Users/ege/Desktop/calibration_images/1/left.png\u001b[39m\u001b[38;5;124m\"\u001b[39m), \n\u001b[0;32m      2\u001b[0m                               cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/Users/ege/Desktop/calibration_images/1/right.png\u001b[39m\u001b[38;5;124m\"\u001b[39m), \n\u001b[0;32m      3\u001b[0m                               evaluation\u001b[38;5;241m.\u001b[39mdetected_labels_and_boxes_result(evaluation\u001b[38;5;241m.\u001b[39mmodel_yolov8,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/Users/ege/Desktop/calibration_images/1/left.png\u001b[39m\u001b[38;5;124m\"\u001b[39m), \n\u001b[0;32m      4\u001b[0m                               evaluation\u001b[38;5;241m.\u001b[39mdetected_labels_and_boxes_result(evaluation\u001b[38;5;241m.\u001b[39mmodel_yolov8,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/Users/ege/Desktop/calibration_images/1/right.png\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m      5\u001b[0m image_info2 \u001b[38;5;241m=\u001b[39m evaluation\u001b[38;5;241m.\u001b[39mstereo_vision_distance_result(cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/Users/ege/Desktop/calibration_images/2/left.png\u001b[39m\u001b[38;5;124m\"\u001b[39m), \n\u001b[0;32m      6\u001b[0m                               cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/Users/ege/Desktop/calibration_images/2/right.png\u001b[39m\u001b[38;5;124m\"\u001b[39m), \n\u001b[0;32m      7\u001b[0m                               evaluation\u001b[38;5;241m.\u001b[39mdetected_labels_and_boxes_result(evaluation\u001b[38;5;241m.\u001b[39mmodel_yolov8,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/Users/ege/Desktop/calibration_images/2/left.png\u001b[39m\u001b[38;5;124m\"\u001b[39m), \n\u001b[0;32m      8\u001b[0m                               evaluation\u001b[38;5;241m.\u001b[39mdetected_labels_and_boxes_result(evaluation\u001b[38;5;241m.\u001b[39mmodel_yolov8,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/Users/ege/Desktop/calibration_images/2/right.png\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[1;32m~\\Smart-Glasses-for-Blind-People\\scripts\\server\\evaluation.py:100\u001b[0m, in \u001b[0;36mstereo_vision_distance_result\u001b[1;34m(image_left, image_right, labels_boxes_json_left, labels_boxes_json_right)\u001b[0m\n\u001b[0;32m     98\u001b[0m cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     99\u001b[0m cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n\u001b[1;32m--> 100\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m'\u001b[39m: labels_boxes_json_left\u001b[38;5;241m.\u001b[39mnames, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclasses\u001b[39m\u001b[38;5;124m\"\u001b[39m: labels_boxes_json_left\u001b[38;5;241m.\u001b[39mboxes\u001b[38;5;241m.\u001b[39mcls, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mboxes\u001b[39m\u001b[38;5;124m\"\u001b[39m: labels_boxes_json_left\u001b[38;5;241m.\u001b[39mboxes\u001b[38;5;241m.\u001b[39mxyxy, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfs\u001b[39m\u001b[38;5;124m\"\u001b[39m: labels_boxes_json_left\u001b[38;5;241m.\u001b[39mboxes\u001b[38;5;241m.\u001b[39mconf, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistances\u001b[39m\u001b[38;5;124m\"\u001b[39m: dists_away}\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'names'"
     ]
    }
   ],
   "source": [
    "calib_case1_img_left_path = \"../../documents/calibration_images/1/left.png\"\n",
    "calib_case1_img_right_path = \"../../documents/calibration_images/1/right.png\"\n",
    "calib_case2_img_left_path = \"../../documents/calibration_images/2/left.png\"\n",
    "calib_case2_img_right_path = \"../../documents/calibration_images/2/right.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423948ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_info1 = evaluation.stereo_vision_distance_result(cv2.imread(calib_case1_img_left_path), \n",
    "                              cv2.imread(calib_case1_img_right_path), \n",
    "                              evaluation.detected_labels_and_boxes_result(evaluation.model_yolov8,calib_case1_img_left_path), \n",
    "                              evaluation.detected_labels_and_boxes_result(evaluation.model_yolov8,calib_case1_img_right_path))\n",
    "image_info2 = evaluation.stereo_vision_distance_result(cv2.imread(calib_case2_img_left_path), \n",
    "                              cv2.imread(calib_case2_img_right_path), \n",
    "                              evaluation.detected_labels_and_boxes_result(evaluation.model_yolov8,calib_case2_img_left_path), \n",
    "                              evaluation.detected_labels_and_boxes_result(evaluation.model_yolov8,calib_case2_img_right_path))\n",
    "print(\"Image 1:\")\n",
    "print(image_info1)\n",
    "print(\"Image 2:\")\n",
    "print(image_info2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805581c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2496ff69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
